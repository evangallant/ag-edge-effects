"""
INPUT DATA
1) a list of s2_blocks, which are the RGB bands for a 20x20 block of pixels (from the 10m resolution S2 satellite imagery) surrounding the target pixel
    These are generated by looking at a set of row, col indices in an S2 image:

    s2_block = data[:, row_start:row_end, col_start:col_end]

    N blocks are appended to an array, which is converted to an np stack:

    s2_blocks = np.stack(s2_blocks)

2) a list of corresponding land cover classes from the USFS dataset at the target pixel's location
    Simple list of integers

OUTPUT
1) An integer representing the class that the model thinks applies to the target pixel
"""
import os
import sys
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from pathlib import Path

model_dir = os.path.dirname(os.path.abspath('__file__'))
src_dir = Path(model_dir).parent
root_dir = Path(src_dir).parent
if str(root_dir) not in sys.path:
    sys.path.append(str(root_dir))
from src.data.CNN.cnn_data_generator import generate_training_samples, generate_roi_list


# Set random seed for reproducibility
torch.manual_seed(42)
np.random.seed(42)

# USFS Land Cover Class Mapping 
class_names = {
    1: "Trees",
    2: "Tall Shrubs & Trees Mix (SEAK Only)", 
    3: "Shrubs & Trees Mix",
    4: "Grass/Forb/Herb & Trees Mix",
    5: "Barren & Trees Mix",
    6: "Tall Shrubs (SEAK Only)",
    7: "Shrubs",
    8: "Grass/Forb/Herb & Shrubs Mix",
    9: "Barren & Shrubs Mix",
    10: "Grass/Forb/Herb",
    11: "Barren & Grass/Forb/Herb Mix",
    12: "Barren or Impervious",
    13: "Snow or Ice",
    14: "Water",
    15: "Non-Processing Area Mask"
}

# Custom Dataset Class
class LandCoverDataset(Dataset):
    def __init__(self, images, labels, transform=None):
        self.images = images
        self.labels = labels
        self.transform = transform
        
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        image = self.images[idx]
        label = self.labels[idx] - 1
        
        # Convert to PyTorch tensor
        image = torch.tensor(image, dtype=torch.float32)
        
        # Apply transformations if any
        if self.transform:
            image = self.transform(image)
            
        return image, label

# CNN Model Definition
class LandCoverCNN(nn.Module):
    def __init__(self, num_classes, block_size=15):
        super(LandCoverCNN, self).__init__()
        
        # Input: 3×block_size×block_size
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)
        self.pool1 = nn.MaxPool2d(2)
        
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)
        self.pool2 = nn.MaxPool2d(2)
        
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(128)
        self.pool3 = nn.MaxPool2d(2)
        
        # Calculate feature dimensions after pooling
        # After 3 pooling layers (each dividing by 2), dimensions become block_size/8
        feature_size = block_size // 8
        # Handle cases where division isn't exact
        if block_size % 8 != 0:
            feature_size = feature_size + 1
            
        self.feature_size = feature_size
        
        # Calculate flattened features size: channels × height × width
        flattened_size = 128 * feature_size * feature_size
        
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(flattened_size, 128)
        self.dropout = nn.Dropout(0.5)
        self.fc2 = nn.Linear(128, num_classes)
        
        # Print network dimensions for verification
        print(f"Block size: {block_size}x{block_size}")
        print(f"Feature map after pooling: 128 × {feature_size} × {feature_size}")
        print(f"Flattened features: {flattened_size}")
        
    def forward(self, x):
        x = self.pool1(F.relu(self.bn1(self.conv1(x))))
        x = self.pool2(F.relu(self.bn2(self.conv2(x))))
        x = self.pool3(F.relu(self.bn3(self.conv3(x))))
        
        # For debugging size issues (optional)
        # print(f"Shape before flatten: {x.shape}")
        
        x = self.flatten(x)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x
    
# Main training function
def train_land_cover_model(s2_blocks, classes, batch_size=32, epochs=50, learning_rate=0.001, block_size=15):
    """
    Train a CNN model to classify land cover types from Sentinel-2 image blocks
    
    Parameters:
    -----------
    s2_blocks : numpy.ndarray
        Array of image blocks with shape (n_samples, 3, block_size, block_size)
    classes : numpy.ndarray
        Array of class labels
    batch_size : int
        Batch size for training
    epochs : int
        Number of training epochs
    learning_rate : float
        Learning rate for optimizer
    block_size : int
        Size of the input image blocks
        
    Returns:
    --------
    model : LandCoverCNN
        Trained CNN model
    history : dict
        Training history (loss and accuracy)
    """
    # 1. Data Preprocessing
    print("Preprocessing data...")
    
    # Normalize the data (assuming typical Sentinel-2 surface reflectance values 0-10000)
    s2_blocks = s2_blocks.astype(np.float32) / 10000.0
    
    # Check if blocks are already in the right format (C, H, W)
    if s2_blocks.shape[1] != 3:
        # If in format (N, H, W, C), transpose to (N, C, H, W)
        if len(s2_blocks.shape) == 4 and s2_blocks.shape[3] == 3:
            s2_blocks = np.transpose(s2_blocks, (0, 3, 1, 2))
    
    # Check data range
    print(f"Data range: {s2_blocks.min()} to {s2_blocks.max()}")
    
    # Split data into training and validation sets
    X_train, X_val, y_train, y_val = train_test_split(
        s2_blocks, classes, test_size=0.2, stratify=classes, random_state=42
    )
    
    print(f"Training samples: {len(X_train)}, Validation samples: {len(X_val)}")
    
    # 2. Create datasets and dataloaders
    # Custom transforms for data augmentation (optional)
    train_transform = transforms.Compose([
        # These transforms work on tensors
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
    ])
    
    train_dataset = LandCoverDataset(X_train, y_train, transform=train_transform)
    val_dataset = LandCoverDataset(X_val, y_val)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size)
    
    # 3. Set up the model
    # Get number of unique classes
    num_classes = len(np.unique(classes))
    print(f"Number of classes: {num_classes}")
    
    # Initialize model, loss, and optimizer
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    total_possible_classes = 15
    model = LandCoverCNN(total_possible_classes, block_size=block_size).to(device)

    # Create weights for all possible classes (1-15)
    class_counts = np.bincount(y_train, minlength=total_possible_classes+1)[1:]  # Skip index 0 since classes start at 1
    
    # Ensure there are no zeros in class_counts (which would cause division by zero)
    min_count = 1  # Minimum count to avoid division by zero
    class_counts = np.maximum(class_counts, min_count)
    
    # Create class weights
    class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float32)
    class_weights = class_weights / class_weights.sum() * len(class_counts)
    class_weights = class_weights.to(device)
    
    criterion = nn.CrossEntropyLoss(weight=class_weights)
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    # Add learning rate scheduler for better convergence
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=5, verbose=True
    )
    
    # 4. Training Loop
    print("Starting training...")
    
    history = {
        'train_loss': [],
        'val_loss': [],
        'train_acc': [],
        'val_acc': []
    }
    
    best_val_loss = float('inf')
    patience = 10
    patience_counter = 0
    
    for epoch in range(epochs):
        # Training phase
        model.train()
        train_loss = 0.0
        correct_train = 0
        total_train = 0
        
        for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs} [Train]"):
            images, labels = images.to(device), labels.to(device)
            
            # Zero the gradients
            optimizer.zero_grad()
            
            # Forward pass
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            # Backward pass and optimize
            loss.backward()
            optimizer.step()
            
            # Track statistics
            train_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total_train += labels.size(0)
            correct_train += (predicted == labels).sum().item()
        
        train_loss = train_loss / len(train_loader)
        train_acc = 100 * correct_train / total_train
        
        # Validation phase
        model.eval()
        val_loss = 0.0
        correct_val = 0
        total_val = 0
        
        with torch.no_grad():
            for images, labels in tqdm(val_loader, desc=f"Epoch {epoch+1}/{epochs} [Val]"):
                images, labels = images.to(device), labels.to(device)
                
                # Forward pass
                outputs = model(images)
                loss = criterion(outputs, labels)
                
                # Track statistics
                val_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total_val += labels.size(0)
                correct_val += (predicted == labels).sum().item()
        
        val_loss = val_loss / len(val_loader)
        val_acc = 100 * correct_val / total_val
        
        # Update learning rate
        scheduler.step(val_loss)
        
        # Save history
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['train_acc'].append(train_acc)
        history['val_acc'].append(val_acc)
        
        print(f"Epoch {epoch+1}/{epochs} - "
              f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% - "
              f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")
        
        # Early stopping
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            # Save the best model
            torch.save(model.state_dict(), 'best_land_cover_model.pth')
            print("Saved best model")
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f"Early stopping after {epoch+1} epochs")
                break
    
    # 5. Load the best model for evaluation
    model.load_state_dict(torch.load('best_land_cover_model.pth'))
    
    return model, history

# Evaluation function
def evaluate_model(model, s2_blocks, classes):
    """
    Evaluate the trained model on test data
    
    Parameters:
    -----------
    model : LandCoverCNN
        Trained model
    s2_blocks : numpy.ndarray
        Test image blocks
    classes : numpy.ndarray
        True class labels
        
    Returns:
    --------
    y_true : numpy.ndarray
        True labels
    y_pred : numpy.ndarray
        Predicted labels
    """
    # Normalize the data
    s2_blocks = s2_blocks.astype(np.float32) / 10000.0
    
    # Create dataset and dataloader
    test_dataset = LandCoverDataset(s2_blocks, classes)
    test_loader = DataLoader(test_dataset, batch_size=32)
    
    device = next(model.parameters()).device
    model.eval()
    
    all_preds = []
    all_true = []
    
    with torch.no_grad():
        for images, labels in tqdm(test_loader, desc="Evaluating"):
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            
            all_preds.extend(predicted.cpu().numpy())
            all_true.extend(labels.cpu().numpy())
    
    return np.array(all_true), np.array(all_preds)

# Visualization functions
def plot_training_history(history):
    """Plot training and validation loss/accuracy curves"""
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    plt.plot(history['train_loss'], label='Train Loss')
    plt.plot(history['val_loss'], label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Loss Curves')
    
    plt.subplot(1, 2, 2)
    plt.plot(history['train_acc'], label='Train Accuracy')
    plt.plot(history['val_acc'], label='Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.legend()
    plt.title('Accuracy Curves')
    
    plt.tight_layout()
    plt.savefig('training_history.png')
    plt.show()

def plot_confusion_matrix(y_true, y_pred, class_names_dict):
    """Plot confusion matrix"""
    cm = confusion_matrix(y_true, y_pred)
    
    # Normalize by row (true labels)
    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    
    # Get unique classes in the data
    unique_classes = np.unique(np.concatenate([y_true, y_pred]))
    class_labels = [class_names_dict.get(int(cls), f"Class {cls}") for cls in unique_classes]
    
    plt.figure(figsize=(12, 10))
    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',
                xticklabels=class_labels, yticklabels=class_labels)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title('Normalized Confusion Matrix')
    plt.tight_layout()
    plt.savefig('confusion_matrix.png')
    plt.show()
    
    # Also print classification report
    print("\nClassification Report:")
    report = classification_report(y_true, y_pred, 
                                  target_names=[class_names_dict.get(int(cls), f"Class {cls}") 
                                              for cls in unique_classes])
    print(report)

# Main execution block
if __name__ == "__main__":
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.abspath(os.path.join(script_dir, '..', '..', '..'))
    s2_data_folder = os.path.join(project_root, 'data', 'raw', 'sentinel2_imagery')
    lc_data_folder = os.path.join(project_root, 'data', 'raw', 'USFS_land_cover')

    roi_names = [
        "kit_carson",
        "cripple_creek",
        "montrose",
        "cortez",
        "durango",
        "lizard_head",
        "ridgway",
        "uncompahgre",
        "yuma",
        "centennial",
        "gunnison",
        "powderhorn",
        "lake_city",
        "monte_vista"
    ]

    roi_list = generate_roi_list(roi_names, s2_data_folder, lc_data_folder)
    block_size = 48

    s2_blocks, classes, s2_block_metadata, utm_coords, albers_coords, lat_lon_coords = generate_training_samples(roi_list, block_size, 50000)
    
    print(f"Loaded {len(s2_blocks)} samples with {len(np.unique(classes))} unique classes")
    print(f"Block shape: {s2_blocks.shape}")
    
    # Check class distribution
    unique_classes, class_counts = np.unique(classes, return_counts=True)
    print("\nClass distribution:")
    for cls, count in zip(unique_classes, class_counts):
        if count == 1:
            print(f"Class {cls} found with {count} (should be 1) samples - exiting early")
            raise ValueError("Class with only 1 sample found")
        
        print(f"Class {cls} ({class_names.get(cls, 'Unknown')}): {count} samples")
    
    # Train model
    model, history = train_land_cover_model(
        s2_blocks, 
        classes,
        batch_size=32,
        epochs=50,
        learning_rate=0.001,
        block_size=block_size
    )
    
    # Visualize training progress
    plot_training_history(history)

    X_train, X_test, y_train, y_test = train_test_split(s2_blocks, classes, test_size=0.2, random_state=42)

    # Pass the test data to evaluate_model
    y_true, y_pred = evaluate_model(model, X_test, y_test)
    
    # Plot confusion matrix
    plot_confusion_matrix(y_true, y_pred, class_names)
    
    print("Training and evaluation complete!")